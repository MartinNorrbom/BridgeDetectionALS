# BridgeDetectionALS

This project is our thesis work for Lantmäteriet. The purpose of this work was to use machine learning for bridge classification in point clouds. The code is not optimised, and it is not designed for production purposes. This work was more focused to find the potentials of using ML for point classification in ALS data.


The ML algorithm used in this work was PointNet++. The work was divided into two parts. The first part was to collect and generate training data for the ML algorithm. The second part was to train up the ML algorithm, test it and analyse the results. The following content is just a description of how to use the code. If you want to understand the concepts of this work, please read the report ... (There will be a link when the report is published)

## Part 1 - data collection and generation

MATLAB was used for the data collection, and there are two main scripts used for the data generation (generateTrainingData.m and combineH5.m). The script generateTrainingData.m is used to download point clouds in LAZ format from Lantmäteriets servers. The data is then generated to grids (tile blocks) in h5 format. The data is from Laserdata skog and cover only areas within Sweden. For more info, check out:

https://www.lantmateriet.se/sv/Kartor-och-geografisk-information/geodataprodukter/produktlista/laserdata-nedladdning-skog/



To generate training data, three steps are needed:

### 1. Download polygons over the selected area.

Go into the webpage: 
https://karthavet.havochvatten.se/visakoordinater/

Mark the polygons over the areas where you want your dataset to be. When the area has been marked, download the polygons as a text file format. There are four types of generation methods to specify which one for each file the names of the downloaded text file must be changed. The first part of the file name must contain "Koordinater", then the generation method numbers. Here are two examples: 

_Koordinater1_bridges_Lund.txt_ or _Koordinater13_bridges_Lund.txt_


Here is a short description of each generation method:
1. Generate only tile blocks that contain bridge points for the entire LAZ files.
2. Generate only tile blocks that do not contain bridge points for the entire LAZ files.
3. Generate tile blocks that are only within the marked polygons.
4. Generate tile blocks over the whole LAZ files and take overlap between tile blocks as an input parameter. This method is designed for the generation of test sets.

To generate the training set, we only used generation method 1 and 3 since method 2 generates large areas. There is also possible to generate multiple polygons within one text file as long as the original coordinates are copied from the web page and replaces the content under "originalrader" to indicate which points are in the same polygon by adding blank rows.

<img src="multiplePolygones.png" alt="multiplePolygones" width="350"/>

### 2. Use generateTrainingData.m to collect and generate the data over the selected polygones.

First, make sure that you have an account to download the data from Lantmäteriet. It is free, and it can be done on this website:
https://opendata.lantmateriet.se/#register

There are three parameters for the generated data:
The side length of the tile blocks.
The number of points per tile block.
The overlap between the tile block, this setting is only supported while using generation method 4.

Run the script when the parameters have been selected. When the file dialogue appears, select the text files that contain the selected polygons. The first time you download the LAZ files over the selected area, you have to log in with a username and password to the server. A message will appear on the command prompt so you can write it there. Otherwise, it is possible to hardcode the username and password into the script "getMissingFilesFromServer.m". When the LAZ files have been downloaded, they will be saved on the computer, so they do not have to be downloaded the next time.

It might take a long time to generate the data since the functions are not optimised, and make sure that you have enough memory on the computer if you are going to generate a large data set.

### 3. Use combineH5.m to shuffle and combine the generated training data.

Run the script, then a file dialog will appear so you can choose the h5 files. Then your training set is ready to be used for the ML algorithms. 

<img src="autoGenerateDataset-1.png" alt="autoGenerateDataset-1" width="350"/>


## Part 2 - ML

Python was used for the ML part. To run PointNet++, Linux is required, but the analysis functions work fine on windows. When you are using PointNet++, make sure that you are using a computer with a GPU with high performance. Otherwise, the training will take a very long time. For the ML part, the first step is to set up PointNet++, the second is to train up the algorithm, the third is to run the test script, and the last is to analyse the results.


### Set up PointNet++



### Train up a model

To train up a model, go to the folder:
Python->Train

Then open train_seg.py and specify the training parameters.

1. Number of features, set "pointFeatures = []" for no more features than the XYZ coordinates. To use one feature set "pointFeatures = ["intensity"]" or "["return_number"]". To use both features set "pointFeatures = ["return_number", "intensity"]".
2. Number of points
3. Max epoch
4. Batch size

There are even more parameter in this script and in the model scripts ("pointnet2_part_seg_(3,4,or 5)Features.py") in the folder
"Python->ML_Algorithms->pointNET2->part_seg".
That can be used for the training.

It took around 4 days to train up a model with a training and validation set of 34 km² with a point density of 1.5 points per m². When the training is finished, the models will be saved in the folder Python->TrainedModels. Move or rename the folder of the trained model if you want to save it. Otherwise, it will be overwritten in the next training.
### Run the test set

To run the trained model in the test set, go to the folder Python->Test. Specify the parameters in "evaluation_seg.py" and select the trained model, then run the python script. After it is complete, a copy of the test set will be added to the folder results. It will contain the prediction of each point in the tile blocks.

### Analyse the results

Specify the files to analyse, voting, filter parameters, and the output folder of the results in "analyse_test_results.py", then run the script. You will receive classification scores, coordinates over predicted bridges, histograms that indicate the quality of the predicted bridges, and point cloud views of the prediction.

<img src="finalModel-1.png" alt="finalModel-1" width="400"/>
